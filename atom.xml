<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[The Tao]]></title>
  <subtitle><![CDATA[Learning every day.]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://phillipchaffee.io/"/>
  <updated>2016-02-17T19:18:05.167Z</updated>
  <id>http://phillipchaffee.io/</id>
  
  <author>
    <name><![CDATA[Phillip Chaffee]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[Understanding Git Rebase]]></title>
    <link href="http://phillipchaffee.io/2016/02/17/Understanding-Git-Rebase/"/>
    <id>http://phillipchaffee.io/2016/02/17/Understanding-Git-Rebase/</id>
    <published>2016-02-17T19:56:09.000Z</published>
    <updated>2016-02-17T19:18:05.167Z</updated>
    <content type="html"><![CDATA[<p>I recently completed my first complicated rebase. I did not understand what a rebase was, but was aware that it was proper work flow to rebase your feature before merge with master.</p>
<p>I read the git documentation and multiple tutorials, but I still did not understand what was going on when I had to make a choice involving a file that was modified by both my feature and master.</p>
<p>This post will give an overview of what a rebase is and attempt to explain what is happening during the process.</p>
<p>##Rebase Overview</p>
<p>A rebase is a simple concept. Imagine a real tree branch. A branch splits off from the main branch half way down. If we were to rebase the branch in the middle onto the main tree branch, we would chop it off the middle, and re-attach it to the very tip of the main branch.</p>
<p>A rebase takes all the changes you have made, and attaches them to the end of the master branch, changing the place your branch diverges from the master branch.</p>
<p>##Confusing Rebase Conflicts</p>
<p>So what happens when you changed a file in your feature, and someone else also changed that file and committed it to master. The rebasing process will ask you which changes you want to take, but the way in which it does offers no explanation of which files are which.</p>
<p>When two files are in conflict, it will stop the process and ask you to fix the conflicts before it proceeds. A run of <code>git status</code> will show the unconflicted files in green, ready to be committed, and the conflicting files in red, needing to be added to the commit, modified, or swapped out for the master branches version.</p>
<p>This is how I understand the next part of the process:</p>
<ul>
<li>Adding the files in red to the commit tells git to take your version of the files.</li>
<li>Using <code>git checkout master file-in-question</code> on the un-added file will tell git to use the master branches file version.</li>
</ul>
<p>I hope this is educational. If I am wrong about any of this please let me know. You can write me at phillipdensmorechaffee@gmail.com.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>I recently completed my first complicated rebase. I did not understand what a rebase was, but was aware that it was proper work flow to r]]>
    </summary>
    
      <category term="-Git -Rebase -Merge" scheme="http://phillipchaffee.io/tags/Git-Rebase-Merge/"/>
    
      <category term="-Git" scheme="http://phillipchaffee.io/categories/Git/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[February 8th, 2016 4:30AM]]></title>
    <link href="http://phillipchaffee.io/2016/02/08/February-8th-2016-4-30AM/"/>
    <id>http://phillipchaffee.io/2016/02/08/February-8th-2016-4-30AM/</id>
    <published>2016-02-08T14:29:20.000Z</published>
    <updated>2016-02-17T19:18:05.167Z</updated>
    <content type="html"><![CDATA[<p>A wind blows to the west<br>And carries with it a seed<br>Where it will go<br>No one may know<br>But go on it will indeed</p>
<p>Sometimes it thinks it controls the wind<br>With a mighty sail it makes its own course<br>Others it resigns<br>To be blown without mind<br>Wherever the wind may force</p>
<p>What it can’t figure out is whether it matters<br>If one tries to control or flows on<br>It seems that control<br>Is nothing at all<br>But the musings of a pawn</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>A wind blows to the west<br>And carries with it a seed<br>Where it will go<br>No one may know<br>But go on it will indeed</p>
<p>Sometime]]>
    </summary>
    
      <category term="Morning thoughts" scheme="http://phillipchaffee.io/tags/Morning-thoughts/"/>
    
      <category term="Poetry" scheme="http://phillipchaffee.io/categories/Poetry/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Coursera Practical Machine Learning Project Write Up]]></title>
    <link href="http://phillipchaffee.io/2015/12/25/Coursera-Practical-Machine-Learning-Project-Write-Up/"/>
    <id>http://phillipchaffee.io/2015/12/25/Coursera-Practical-Machine-Learning-Project-Write-Up/</id>
    <published>2015-12-25T18:59:34.000Z</published>
    <updated>2015-12-25T14:06:56.796Z</updated>
    <content type="html"><![CDATA[<p>This is the write up for the final project of the Practical Machine Learning course taught by John Hopkins on Coursera.</p>
<p>The project was to build a predictive model using sensor data from <a href="http://groupware.les.inf.puc-rio.br/har" target="_blank" rel="external">this</a> paper.</p>
<hr>
<p>title: “Practical Machine Learning Write-Up”<br>author: “Phillip Chaffee”<br>date: “December 20, 2015”</p>
<h2 id="output_3A_html_document"><a href="#output_3A_html_document" class="headerlink" title="output: html_document"></a>output: html_document</h2><p>#Abstract</p>
<p>This project involves a set of sensor data that pertain to a dumbbell lift. Each instance has sensor readings, and a classe. The classe is a rating of lifting form. A is a proper lift. B though E are common mistakes. The goal is to build an algorithm that will predict a lift’s classe given sensor data. This project subsetted the data to only the quality variables, and then built a random forest.</p>
<p>#Analysis</p>
<p>Analysis of the training data set showed that there were several instances of non values, characterized by NA, “”, “ “, and #DIV/0!. Therefore the first option performed was to read the data set in correctly.</p>
<figure class="highlight"><figcaption><span>Load libraries and read data, cache=TRUE&#125;</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">require(caret)&#10;download.file(&#34;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&#34;, destfile = &#34;pml-training.csv&#34;)&#10;training &#60;- read.csv(&#34;pml-training.csv&#34;, na.strings = c(&#34;NA&#34;,&#34;&#34;,&#34; &#34;,&#34;#DIV/0!&#34;))</span><br></pre></td></tr></table></figure>
<p>The next step was to get an idea of the variables in the training set.</p>
<figure class="highlight"><figcaption><span>Analysis 1, cache=TRUE&#125;</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">colnames(training)</span><br></pre></td></tr></table></figure>
<p>It seemed that the first seven variables had more to do with labeling the data than describing the lifts, so they were removed. To clean the data set, the columns with more than 100 NA values were also removed.</p>
<figure class="highlight"><figcaption><span>Analysis 2/Clean, cache=TRUE&#125;</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">training &#60;- training[,-c(1,2,3,4,5,6,7)]&#10;goodData &#60;- colSums(is.na(training)) &#60; 100&#10;training &#60;- training[,goodData]</span><br></pre></td></tr></table></figure>
<p>That provides 52 high quality variables to work with, excluding the classe column. This is a great set to build a model on.</p>
<p>#Methods</p>
<p>To build the model the caret package was used. A random forest was built, using boot632 resampling.</p>
<figure class="highlight"><figcaption><span>Model training, cache=TRUE&#125;</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modFit &#60;- train(classe~., data=training, trControl=trainControl(method=&#34;boot632&#34;))</span><br></pre></td></tr></table></figure>
<p>#Results</p>
<p>This model provides very high in sample accuracy as well as out of sample accuracy.</p>
<figure class="highlight"><figcaption><span>In sample summary, cache=TRUE&#125;</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modFit$finalModel&#10;modFit$results</span><br></pre></td></tr></table></figure>
<p>This model correctly predicted 20/20 of the training set classes.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>This is the write up for the final project of the Practical Machine Learning course taught by John Hopkins on Coursera.</p>
<p>The projec]]>
    </summary>
    
      <category term="Coursera" scheme="http://phillipchaffee.io/tags/Coursera/"/>
    
      <category term="Data Science" scheme="http://phillipchaffee.io/tags/Data-Science/"/>
    
      <category term="John Hopkins" scheme="http://phillipchaffee.io/tags/John-Hopkins/"/>
    
      <category term="Machine Learning" scheme="http://phillipchaffee.io/tags/Machine-Learning/"/>
    
      <category term="Data Science" scheme="http://phillipchaffee.io/categories/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Coursera Data Science 12/20/15]]></title>
    <link href="http://phillipchaffee.io/2015/12/21/Coursera-Data-Science-12-20-15/"/>
    <id>http://phillipchaffee.io/2015/12/21/Coursera-Data-Science-12-20-15/</id>
    <published>2015-12-21T01:14:32.000Z</published>
    <updated>2015-12-20T20:33:39.348Z</updated>
    <content type="html"><![CDATA[<p>I have solved my previous problem of not being able to apply my random forest model to the testing set. </p>
<p>I was originally cleaning the training set by removing all the un-needed data, e.g. row number, participant name, time frame. Then I was subsetting the data frame by using the caret package’s<br><code>nearZeroVar()</code>. It was removing most of the columns that were overly populated by NA, but not enough of them.</p>
<p>I fixed the problem by removing all the columns with more than 100 NA values, leaving me with 52 variables to predict with. I built a random forest algorithm with this data using caret’s <code>train()</code> function.<br>The final model used 27 random predictors at each node, and had a .99585 in sample accuracy.</p>
<p>I was afraid that I had over fitted the model and was tempted to scrap it, but I thought I would at least give it one try. I applied it to the testing set and got perfect accuracy. This was the first time I had<br>applied any model to the testing set, so my model was not at all tuned to the its noise. The testing set was only twenty rows in length, and I am sure had it been longer I would have gotten some wrong<br>predictions.</p>
<p>I am very impressed with the random forests algorithm and plan to use it again.</p>
<p>I am now attempting to understand the model. It is a very difficult task. You can pull single trees out of the model and analyze them, but there are so many trees it would impossible to go through them all.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>I have solved my previous problem of not being able to apply my random forest model to the testing set. </p>
<p>I was originally cleaning]]>
    </summary>
    
      <category term="Code" scheme="http://phillipchaffee.io/tags/Code/"/>
    
      <category term="Data Science" scheme="http://phillipchaffee.io/tags/Data-Science/"/>
    
      <category term="Random Forests" scheme="http://phillipchaffee.io/tags/Random-Forests/"/>
    
      <category term="Data Science" scheme="http://phillipchaffee.io/categories/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Coursera Data Science - 12/19/15]]></title>
    <link href="http://phillipchaffee.io/2015/12/20/R-probs/"/>
    <id>http://phillipchaffee.io/2015/12/20/R-probs/</id>
    <published>2015-12-20T01:51:19.000Z</published>
    <updated>2015-12-20T20:33:58.111Z</updated>
    <content type="html"><![CDATA[<p>I am current taking the class Practical Machine Learning on Coursera offered by John Hopkins University.</p>
<p>The course project is to take sensor data from a study designed to evaluate the correctness in form of dumbbell exercises and build a machine learning algorithm that will predict how well dumbbell lift x was performed.<br>The individual lifts are categorized into five classes: A, B, C, D, E. A is a proper lift. The other four are common mistakes made in dumbbell lifting. The algorithm should predict the class of lift x. </p>
<p>I have processed the training set, and built an algoritm based upon it. The problem arises when I attempt to predict the values of the testing set using <code>predict()</code>. Several of the columns in the testing set<br>contain purely NA values, and cause <code>predict()</code> to throw an error.</p>
<p>I am at a loss because I know that in order to predict correctly the training and test sets should be read in and processed the exact same way. I do not see a way around this. If I process them identically I end up<br>with entire NA columns in the testing set. If I do not the prediction will not work.</p>
<p>It may be time for a break. I will report back later.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>I am current taking the class Practical Machine Learning on Coursera offered by John Hopkins University.</p>
<p>The course project is to ]]>
    </summary>
    
      <category term="Coursera" scheme="http://phillipchaffee.io/tags/Coursera/"/>
    
      <category term="Machine Learning" scheme="http://phillipchaffee.io/tags/Machine-Learning/"/>
    
      <category term="R" scheme="http://phillipchaffee.io/tags/R/"/>
    
      <category term="Data Science" scheme="http://phillipchaffee.io/categories/Data-Science/"/>
    
  </entry>
  
</feed>
